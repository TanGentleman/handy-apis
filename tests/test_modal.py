"""Manual tests for the content-scraper Modal API endpoints.

Usage:
    python tests/test_modal.py           # Run all tests sequentially
    python tests/test_modal.py parallel  # Fetch all sites in parallel
    python tests/test_modal.py bulk      # Test bulk job endpoints
"""

import asyncio
import sys
import time

import httpx

# Import API URL from centralized config (generated by setup.py)
from config.settings import get_api_url

# Resolve API URL at module load - will fail with clear error if not configured
API_BASE = get_api_url()

DEFAULT_TIMEOUT = 15.0
CONTENT_TIMEOUT = 180.0
BULK_TIMEOUT = 300.0
MAX_CONCURRENCY = 50


def fetch_sites_with_paths() -> list[dict]:
    """Fetch all sites with their test paths from the API."""
    resp = httpx.get(
        f"{API_BASE}/sites",
        params={"include_test_paths": "true"},
        timeout=DEFAULT_TIMEOUT,
    )
    resp.raise_for_status()
    return resp.json()["sites"]


async def _fetch_with_semaphore(
    client: httpx.AsyncClient,
    semaphore: asyncio.Semaphore,
    site_id: str,
    path: str,
) -> dict:
    """Fetch content for a single site with semaphore control."""
    async with semaphore:
        try:
            resp = await client.get(
                f"{API_BASE}/sites/{site_id}/content",
                params={"path": path},
            )
            if resp.status_code != 200:
                return {"site_id": site_id, "error": f"HTTP {resp.status_code}"}
            data = resp.json()
            return {
                "site_id": site_id,
                "path": data["path"],
                "content_length": data["content_length"],
                "from_cache": data.get("from_cache", False),
            }
        except Exception as e:
            return {"site_id": site_id, "error": str(e)}


async def fetch_all_parallel() -> tuple[dict, bool]:
    """Fetch content from all providers in parallel using semaphore."""
    sites = fetch_sites_with_paths()
    print(
        f"\nFetching content from {len(sites)} sites (max concurrency: {MAX_CONCURRENCY})..."
    )
    print("=" * 60)

    semaphore = asyncio.Semaphore(MAX_CONCURRENCY)
    results = {}
    all_ok = True

    async with httpx.AsyncClient(timeout=CONTENT_TIMEOUT) as client:
        tasks = [
            _fetch_with_semaphore(client, semaphore, site["id"], site["testPath"])
            for site in sites
        ]
        responses = await asyncio.gather(*tasks)

    for result in responses:
        site_id = result["site_id"]
        results[site_id] = result
        if "error" in result:
            print(f"  {site_id}: ✗ {result['error']}")
            all_ok = False
        else:
            status = "from_cache" if result["from_cache"] else "fresh"
            print(f"  {site_id}: ✓ {result['content_length']} chars ({status})")

    return results, all_ok


async def verify_all_cached() -> bool:
    """Verify all providers return cached responses."""
    print("\nVerifying cache status...")
    print("=" * 60)

    sites = fetch_sites_with_paths()
    semaphore = asyncio.Semaphore(MAX_CONCURRENCY)
    all_cached = True

    async with httpx.AsyncClient(timeout=CONTENT_TIMEOUT) as client:
        tasks = [
            _fetch_with_semaphore(client, semaphore, site["id"], site["testPath"])
            for site in sites
        ]
        results = await asyncio.gather(*tasks)

    for result in results:
        site_id = result["site_id"]
        if "error" in result:
            print(f"  {site_id}: ✗ {result['error']}")
            all_cached = False
        elif result.get("from_cache"):
            print(f"  {site_id}: ✓ cached")
        else:
            print(f"  {site_id}: ✗ not cached")
            all_cached = False

    return all_cached


async def run_parallel_tests():
    """Fetch all sites in parallel, then verify caching."""
    print(f"Testing API: {API_BASE}")

    _, all_ok = await fetch_all_parallel()
    if not all_ok:
        print("\n⚠ Some providers failed")

    all_cached = await verify_all_cached()

    print("\n" + "=" * 60)
    print("✓ All cached!" if all_cached else "✗ Some not cached")
    print("=" * 60)


def test_jobs_list():
    """Test GET /jobs endpoint."""
    print("\nJobs list...")
    resp = httpx.get(f"{API_BASE}/jobs", timeout=DEFAULT_TIMEOUT)
    if resp.status_code == 200:
        data = resp.json()
        print(f"  ✓ {len(data.get('jobs', []))} jobs")
        return data
    else:
        print(f"  ✗ HTTP {resp.status_code}")
        return None


def test_job_status(job_id: str) -> dict | None:
    """Test GET /jobs/{job_id} endpoint."""
    print(f"\nJob status ({job_id})...")
    resp = httpx.get(f"{API_BASE}/jobs/{job_id}", timeout=DEFAULT_TIMEOUT)
    if resp.status_code == 200:
        data = resp.json()
        print(f"  ✓ status={data['status']}, progress={data['progress_pct']}%")
        return data
    elif resp.status_code == 404:
        print("  ✗ Job not found")
        return None
    else:
        print(f"  ✗ HTTP {resp.status_code}")
        return None


def test_bulk_submit(urls: list[str], max_age: int | None = None) -> str | None:
    """Test POST /jobs/bulk endpoint."""
    print(f"\nBulk submit ({len(urls)} URLs)...")
    payload = {"urls": urls}
    if max_age is not None:
        payload["max_age"] = max_age
    resp = httpx.post(
        f"{API_BASE}/jobs/bulk",
        json=payload,
        timeout=BULK_TIMEOUT,
    )
    if resp.status_code == 200:
        data = resp.json()
        job_id = data.get("job_id")
        if job_id:
            print(f"  ✓ job_id={job_id}, batches={data.get('batches', 0)}")
            assert "input" in data, "Missing 'input' in response"
            assert "status" in data, "Missing 'status' in response"
            return job_id
        else:
            print(f"  ✓ No job needed: {data.get('message', 'completed')}")
            return None
    else:
        print(f"  ✗ HTTP {resp.status_code}: {resp.text[:100]}")
        return None


def wait_for_job(job_id: str, timeout_seconds: int = 120) -> dict | None:
    """Poll job status until completed or timeout."""
    print(f"\nWaiting for job {job_id}...")
    start = time.time()
    last_pct = -1
    while time.time() - start < timeout_seconds:
        status = test_job_status(job_id)
        if status is None:
            return None
        if status["status"] == "completed":
            progress = status.get("progress", {})
            success = progress.get("success", 0)
            skipped = progress.get("skipped", 0)
            failed = progress.get("failed", 0)
            print(f"  ✓ Completed in {status['elapsed_seconds']}s "
                  f"(success={success}, skipped={skipped}, failed={failed})")
            return status
        curr_pct = status.get("progress_pct", 0)
        if curr_pct == last_pct:
            time.sleep(2)
        else:
            last_pct = curr_pct
            time.sleep(1)
    print(f"  ✗ Timeout after {timeout_seconds}s")
    return None


def run_bulk_tests():
    """Test bulk job endpoints."""
    print(f"Testing Bulk Job API: {API_BASE}")
    print("=" * 60)

    test_jobs_list()

    print("\nTesting non-existent job...")
    test_job_status("nonexistent")

    print("\nTesting empty URL list...")
    resp = httpx.post(
        f"{API_BASE}/jobs/bulk",
        json={"urls": []},
        timeout=DEFAULT_TIMEOUT,
    )
    if resp.status_code == 400:
        print("  ✓ Correctly rejected empty URLs")
    else:
        print(f"  ✗ Expected 400, got {resp.status_code}")

    print("\nTesting unknown URLs...")
    job_id = test_bulk_submit(["https://unknown-site.example.com/page"])
    if job_id is None:
        print("  ✓ No job created for unknown URLs")

    print("\nTesting asset URLs...")
    test_bulk_submit([
        "https://docs.modal.com/file.pdf",
        "https://docs.modal.com/image.png",
    ])

    print("\nTesting valid URLs...")
    valid_urls = [
        "https://modal.com/docs/guide",
        "https://modal.com/docs/examples",
    ]
    job_id = test_bulk_submit(valid_urls)
    if job_id:
        final_status = wait_for_job(job_id, timeout_seconds=60)
        if final_status:
            print(f"\nFinal progress: {final_status['progress']}")
            if final_status.get("errors"):
                print(f"Errors: {final_status['errors'][:3]}")

    print("\nTesting with cache (high max_age)...")
    job_id = test_bulk_submit(valid_urls, max_age=86400 * 7)
    if job_id:
        final_status = wait_for_job(job_id, timeout_seconds=30)
        if final_status:
            skipped = final_status.get("progress", {}).get("skipped", 0)
            if skipped > 0:
                print(f"  ✓ Cache working: {skipped} URLs skipped (already cached)")

    print("\n" + "=" * 60)
    test_jobs_list()

    print("\n" + "=" * 60)
    print("Bulk tests completed!")


def run_sequential_tests():
    """Run all tests sequentially with verbose output."""
    print(f"Testing API: {API_BASE}")
    print("=" * 60)

    tests = [
        ("Root", f"{API_BASE}/", None),
        ("Health", f"{API_BASE}/health", None),
        ("Sites", f"{API_BASE}/sites", None),
    ]

    for name, url, params in tests:
        print(f"\n{name} endpoint...")
        resp = httpx.get(url, params=params, timeout=DEFAULT_TIMEOUT)
        if resp.status_code == 200:
            print(f"  ✓ {resp.json()}")
        else:
            print(f"  ✗ HTTP {resp.status_code}: {resp.text[:100]}")

    print("\nLinks (modal)...")
    resp = httpx.get(f"{API_BASE}/sites/modal/links", timeout=CONTENT_TIMEOUT)
    if resp.status_code == 200:
        print(f"  ✓ {resp.json()['count']} links")
    else:
        print(f"  ✗ HTTP {resp.status_code}")

    print("\nContent (modal /guide)...")
    resp = httpx.get(
        f"{API_BASE}/sites/modal/content",
        params={"path": "/guide"},
        timeout=CONTENT_TIMEOUT,
    )
    if resp.status_code == 200:
        print(f"  ✓ {resp.json()['content_length']} chars")
    else:
        print(f"  ✗ HTTP {resp.status_code}")

    test_jobs_list()

    print("\n" + "=" * 60)
    print("Sequential tests completed!")


if __name__ == "__main__":
    if len(sys.argv) > 1:
        if sys.argv[1] == "parallel":
            asyncio.run(run_parallel_tests())
        elif sys.argv[1] == "bulk":
            run_bulk_tests()
        else:
            print(f"Unknown command: {sys.argv[1]}")
            print("Usage: python tests/test_modal.py [parallel|bulk]")
            sys.exit(1)
    else:
        run_sequential_tests()
